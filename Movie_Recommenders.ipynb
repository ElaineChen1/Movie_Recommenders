{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import turicreate\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Read movies.csv, ratings.csv, tags.csv\n",
    "movies = pd.read_csv('../input/ml20mzip/ml-20m/movies.csv')\n",
    "ratings = pd.read_csv('../input/ml20mzip/ml-20m/ratings.csv')\n",
    "tags = pd.read_csv('../input/ml20mzip/ml-20m/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging movies and tags\n",
    "# Groupby movieId\n",
    "merged_tags = tags[['movieId','tag']].groupby('movieId').agg({'tag': lambda x: ' '.join([str(x_) for x_ in x])})\n",
    "movie_tag_new = pd.merge(movies, merged_tags, how=\"left\", on=\"movieId\")\n",
    "movie_tag_new['tag'] = movie_tag_new['tag'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content filtering on Metadata\n",
    "movie_tag_new['genres'].apply(lambda s: s.replace('|', ' '))\n",
    "movie_tag_new['desc'] = movie_tag_new['genres'].apply(lambda s: s.replace('|', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create User Movie Matrix\n",
    "N_ratings = len(ratings)\n",
    "user_movies_data = ratings.iloc[:N_ratings//10].pivot(index='movieId', columns='userId', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of movieId based on 'user_movies_data'\n",
    "movie_tag_new = movie_tag_new.loc[movie_tag_new.movieId.isin(user_movies_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer on Metadata\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(movie_tag_new['desc'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=movie_tag_new.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TruncatedSVD for Content filter\n",
    "# Create latent matrix 1\n",
    "svd = TruncatedSVD(n_components=18)\n",
    "latent_matrix_1 = svd.fit_transform(tfidf_df)\n",
    "n = 19\n",
    "latent_matrix_1_df = pd.DataFrame(latent_matrix_1[:, 0:n], index=movie_tag_new['title'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative filtering\n",
    "# Create latent matrix 2\n",
    "latent_matrix_2 = svd.fit_transform(user_movies_data)\n",
    "latent_matrix_2_df = pd.DataFrame(latent_matrix_2, index=movies.loc[movies['movieId'].isin(user_movies_data.index)]['title'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Recommendation System\n",
    "def recommend_similar_movies(title):\n",
    "    a_1 = np.array(latent_matrix_1_df.loc[title]).reshape(1, -1)\n",
    "    a_2 = np.array(latent_matrix_2_df.loc[title]).reshape(1, -1)\n",
    "\n",
    "    # calculate the similartity of this movie with the others in the list\n",
    "    score_content = cosine_similarity(latent_matrix_1_df, a_1).reshape(-1)\n",
    "    score_collab = cosine_similarity(latent_matrix_2_df, a_2).reshape(-1)\n",
    "\n",
    "    # hybrid score: an average measure of both content and collaborative \n",
    "    hybrid_score = (score_content + score_collab) / 2\n",
    "\n",
    "    # form a data frame of similar movies \n",
    "    dictDF = {'content': score_content, 'collab': score_collab, 'hybrid': hybrid_score}\n",
    "    similar_movies = pd.DataFrame(dictDF, index=latent_matrix_2_df.index)\n",
    "\n",
    "    #sort it on the basis of either: content, collaborative or hybrid, here : content\n",
    "    similar_movies.sort_values('content', ascending=False, inplace=True)\n",
    "    print(similar_movies)\n",
    "    \n",
    "    return dictDF\n",
    "\n",
    "recommend_similar_movies(latent_matrix_1_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turicreate\n",
    "# Popularity Recommender - Cold Start problem\n",
    "# every new user will get the same recommendations\n",
    "model = turicreate.popularity_recommender.create(ratings, user_id='userId', item_id='movieId', target='rating')\n",
    "\n",
    "# Recommend some top 5 movies to users 1, 2, 3, 4, 5\n",
    "pop_rec = model.recommend(users=[1,2,3,4,5], k=5)\n",
    "pop_rec.print_rows(num_rows=25, num_columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item Similarity Recommender\n",
    "# Making recommendations for users 1, 2, 3, 4, 5\n",
    "sim_model = turicreate.item_similarity_recommender.create(ratings, user_id='userId', item_id='movieId', target='rating', similarity_type='cosine')\n",
    "sim = sim_model.recommend(users=[1,2,3,4,5], k=5)\n",
    "sim.print_rows(num_rows=25, num_columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Factorization Recommender\n",
    "class MF():\n",
    "\n",
    "    # Initializing the user-movie rating matrix, no. of latent features, alpha and beta.\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    # Initializing user-feature and movie-feature matrix \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # List of training samples\n",
    "        self.samples = [\n",
    "        (i, j, self.R[i, j])\n",
    "        for i in range(self.num_users)\n",
    "        for j in range(self.num_items)\n",
    "        if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    # Computing total mean squared error\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Ratings for user i and moive j\n",
    "    def get_rating(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_matrix(self):\n",
    "        return mf.b + mf.b_u[:,np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= np.array(user_movies_data)\n",
    "mf = MF(R, K=20, alpha=0.001, beta=0.01, iterations=100)\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(mf.full_matrix())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise\n",
    "N_ratings = len(ratings)\n",
    "user_movies_data = ratings.iloc[:N_ratings//10].pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
    "\n",
    "Mapping_file = dict(zip(movie_tag_new['title'].tolist(), movie_tag_new['movieId'].tolist()))\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_user_rating(ui,algorithm = svd):\n",
    "    if ui in ratings.userId.unique():\n",
    "        ui_list = ratings[ratings.userId == ui].movieId.tolist()\n",
    "        d = {k: v for k,v in Mapping_file.items() if not v in ui_list}        \n",
    "        predictedL = []\n",
    "        for i, j in d.items():     \n",
    "            predicted = algorithm.predict(ui, j)\n",
    "            predictedL.append((i, predicted[3])) \n",
    "        pdf = pd.DataFrame(predictedL, columns = ['movies', 'ratings'])\n",
    "        pdf.sort_values('ratings', ascending=False, inplace=True)  \n",
    "        pdf.set_index('movies', inplace=True)    \n",
    "        return pdf.head(10)        \n",
    "    else:\n",
    "        print(\"User Id does not exist in the list!\")\n",
    "        return pred_user_rating\n",
    "userId = 1\n",
    "pred_user_rating(userId)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
